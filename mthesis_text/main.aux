\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Organization of this work}{5}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{5}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}How do I read this?}{6}{section.1.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Gaussian Process regression}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}A weight space view for Gaussian Processes}{7}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Standard Bayesian linear regression}{7}{subsection.2.1.1}}
\newlabel{linearmodel}{{2.1}{7}{Standard Bayesian linear regression}{equation.2.1.1}{}}
\newlabel{wprior}{{2.3}{7}{Standard Bayesian linear regression}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Kernel functions in feature space}{8}{subsection.2.1.2}}
\newlabel{torewrite}{{2.8}{8}{Kernel functions in feature space}{equation.2.1.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}A function space view for Gaussian Processes}{8}{section.2.2}}
\newlabel{sqexp}{{2.17}{9}{A function space view for Gaussian Processes}{equation.2.2.17}{}}
\newlabel{fprior}{{2.18}{9}{A function space view for Gaussian Processes}{equation.2.2.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Three sampled Gaussian Process priors using the Squared Exponential kernel.\relax }}{10}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:drawPrior}{{2.1}{10}{Three sampled Gaussian Process priors using the Squared Exponential kernel.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Prediction using a Gaussian Process prior}{10}{section.2.3}}
\newlabel{pred}{{2.3}{10}{Prediction using a Gaussian Process prior}{section.2.3}{}}
\newlabel{conditioning}{{1}{10}{Prediction using a Gaussian Process prior}{mydef.1}{}}
\newlabel{hierarchical}{{2.27}{11}{Prediction using a Gaussian Process prior}{equation.2.3.27}{}}
\newlabel{hierarchical2}{{2.28}{11}{Prediction using a Gaussian Process prior}{equation.2.3.28}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gaussian regressor pseudo-code.\relax }}{12}{algorithm.1}}
\newlabel{alg}{{1}{12}{Gaussian regressor pseudo-code.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}A toy example of Gaussian Process regression}{13}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}On covariance functions}{14}{section.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A fitted Gaussian Process regressor to samples of the sine function.\relax }}{15}{figure.caption.3}}
\newlabel{fig:GPsine}{{2.2}{15}{A fitted Gaussian Process regressor to samples of the sine function.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}A zoo of covariance functions}{17}{subsection.2.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Behaviour of different stationary covariance functions with the default parameters in pyGPGO.\relax }}{18}{figure.caption.4}}
\newlabel{fig:zoo}{{2.3}{18}{Behaviour of different stationary covariance functions with the default parameters in pyGPGO.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Hyperparameter optimization}{18}{section.2.5}}
\newlabel{hyper}{{2.5}{18}{Hyperparameter optimization}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Type II Maximum Likelihood}{18}{subsection.2.5.1}}
\newlabel{posteriorparam}{{2.36}{18}{Type II Maximum Likelihood}{equation.2.5.36}{}}
\newlabel{posteriorhyper}{{2.37}{19}{Type II Maximum Likelihood}{equation.2.5.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{Another toy example: Optimizing the characteristic length-scale}{20}{section*.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Cross validation}{20}{subsection.2.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Log-marginal likelihood and its gradient w.r.t to the characteristic length-scale. Notice there seems to be an optimal point at around $l = 1.4$.\relax }}{21}{figure.caption.6}}
\newlabel{fig:logmarginal}{{2.4}{21}{Log-marginal likelihood and its gradient w.r.t to the characteristic length-scale. Notice there seems to be an optimal point at around $l = 1.4$.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Bayesian optimization}{23}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Preliminaries}{23}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The bayesian optimization framework}{23}{section.3.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Bayesian optimization framework.\relax }}{24}{algorithm.2}}
\newlabel{bayesopt}{{2}{24}{Bayesian optimization framework.\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}On acquisition functions}{24}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Improvement-based policies}{24}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Optimistic policies}{25}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Information-based policies}{25}{subsection.3.3.3}}
\newlabel{acqes}{{3.10}{25}{Information-based policies}{equation.3.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Acquisition function portfolios}{26}{subsection.3.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Example: visualizing the behaviour of an acquisition function}{26}{subsection.3.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.6}Example: why does Bayesian Optimization work?}{27}{subsection.3.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Role of GP hyperparameters in optimization}{27}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Acquisition function behaviour for Expected Improvement, Probability of Improvement, GP-UCB ($\beta = .5$) and GP-UCB($\beta = 1.5$) in the sine function example.\relax }}{28}{figure.caption.7}}
\newlabel{fig:acqzoo}{{3.1}{28}{Acquisition function behaviour for Expected Improvement, Probability of Improvement, GP-UCB ($\beta = .5$) and GP-UCB($\beta = 1.5$) in the sine function example.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A visual explanation on why Bayesian optimization is efficient at exploring the space. It ignores all the input space where the UPB is lower than the point with maximum LCB.\relax }}{29}{figure.caption.8}}
\newlabel{fig:explanation}{{3.2}{29}{A visual explanation on why Bayesian optimization is efficient at exploring the space. It ignores all the input space where the UPB is lower than the point with maximum LCB.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Optimizing the acquisition function}{30}{section.3.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}A complete 1D example: optimizing the sine function}{30}{section.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}A step by step example: optimizing the Rossenbrock function}{30}{section.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A 2D representation of the Rossenbrock function.\relax }}{31}{figure.caption.9}}
\newlabel{fig:rosen}{{3.3}{31}{A 2D representation of the Rossenbrock function.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Six complete optimization epochs in the Bayesian Optimization framework for the target Rossenbrock 2D function.\relax }}{32}{figure.caption.10}}
\newlabel{fig:2dstep}{{3.4}{32}{Six complete optimization epochs in the Bayesian Optimization framework for the target Rossenbrock 2D function.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments}{33}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef\minted@oldcachelist{,
  default.pygstyle,
  default-pyg-prefix.pygstyle,
  4BC65608FD2763E7C231A03E58CF90C9F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  85B43FECD3A9742F76E3BCC90D3C48A7F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  CBAFD97C67C91ADDAEA34D3DAF0D4007F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  990BF002D0D2280EAC881D74A601ABB2F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  71F3DE110298F09031B3F38D0484E76DF25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  1E29121FDD465C160E40FEBB4C5ACF71F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  21283FDE4A89D22A1CC5774B4CB55E0FF25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  4114330659FF80695AA0581023CABCDEF25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  01846CE0AB08FBB5370F551BDD8700E4F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  778010B1D483D75C07C76F2DA0721C6BF25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  69039E575068EBA51D5DDA94862D7B08F25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex,
  C3FEF1F24A4C8C42E29EB147312F79BAF25D47A0ADF8F08BC84ACD63E58FD4EA.pygtex}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}pyGPGO: A simple Python Package for Bayesian Optimization}{35}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
