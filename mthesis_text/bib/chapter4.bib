@article{Verikas2011,
abstract = {Random forests (RF) has become a popular technique for classification, prediction, studying variable importance, variable selection, and outlier detection. There are numerous application examples of RF in a variety of fields. Several large scale comparisons including RF have been performed. There are numerous articles, where variable importance evaluations based on the variable importance measures available from RF are used for data exploration and understanding. Apart from the literature survey in RF area, this paper also presents results of new tests regarding variable rankings based on RF variable importance measures. We studied experimentally the consistency and generality of such rankings. Results of the studies indicate that there is no evidence supporting the belief in generality of such rankings. A high variance of variable importance evaluations was observed in the case of small number of trees and small data sets. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Verikas, A. and Gelzinis, A. and Bacauskiene, M.},
doi = {10.1016/j.patcog.2010.08.011},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Classifier,Data proximity,Random forests,Variable importance,Variable selection},
number = {2},
pages = {330--349},
title = {{Mining data with random forests: A survey and results of new tests}},
volume = {44},
year = {2011}
}

@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising successâ€”they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {{Bergstra}, James and {Yoshua Bengio}, Umontrealca},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}

@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}

@article{Cortes1995,
abstract = {Oil/water partition coefficient (log P) is one of the key points for lead compound to be drug. In silico log P models based solely on chemical structures have become an important part of modern drug discovery. Here, we report support vector machines, radial basis function neural networks, and multiple linear regression methods to investigate the correlation between partition coefficient and physico-chemical descriptors for a large data set of compounds. The correlation coefficient r (2) between experimental and predicted log P for training and test sets by support vector machines, radial basis function neural networks, and multiple linear regression is 0.92, 0.90, and 0.88, respectively. The results show that non-linear support vector machines derives statistical models that have better prediction ability than those of radial basis function neural networks and multiple linear regression methods. This indicates that support vector machines can be used as an alternative modeling tool for quantitative structure-property/activity relationships studies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1023/A:1022627411411},
eprint = {arXiv:1011.1669v3},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
number = {3},
pages = {273--297},
pmid = {19549084},
title = {{Support-Vector Networks}},
volume = {20},
year = {1995}
}

@article{Chang2011,
abstract = {LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems, theoretical convergence, multi-class classification, probability estimates, and parameter selection are discussed in detail},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Chang, Chih-chung and Lin, Chih-jen},
doi = {10.1145/1961189.1961199},
eprint = {0-387-31073-8},
isbn = {2157-6904},
issn = {21576904},
journal = {ACM Transactions on Intelligent Systems and Technology (TIST)},
keywords = {classification,libsvm,optimization,regression,support vector ma-},
pages = {1--39},
pmid = {371},
title = {{LIBSVM : A Library for Support Vector Machines}},
volume = {2},
year = {2011}
}

@article{Kennel2004,
abstract = {Many data-based statistical algorithms require that one find $\backslash$textit{\{}near or nearest neighbors{\}} to a given vector among a set of points in that vector space, usually with Euclidean topology. The k-d data structure and search algorithms are the generalization of classical binary search trees to higher dimensional spaces, so that one may locate near neighbors to an example vector in {\$}O(\backslashlog N){\$} time instead of the brute-force O(N) time, with {\$}N{\$} being the size of the data base. KDTREE2 is a Fortran 95 module, and a parallel set of C++ classes which implement tree construction and search routines to find either a set of {\$}m{\$} nearest neighbors to an example, or all the neighbors within some Euclidean distance {\$}r.{\$} The two versions are independent and function fully on their own. Considerable care has been taken in the implementation of the search methods, resulting in substantially higher computational efficiency (up to an order of magnitude faster) than the author's previous Internet-distributed version. Architectural improvements include rearrangement for memory cache-friendly performance, heap-based priority queues for large {\$}m{\$}searches, and more effective pruning of search paths by geometrical constraints to avoid wasted effort. The improvements are the most potent in the more difficult and slowest cases: larger data base sizes, higher dimensionality manifolds containing the data set, and larger numbers of neighbors to search for. The C++ implementation requires the Standard Template Library as well as the BOOST C++ library be installed.},
archivePrefix = {arXiv},
arxivId = {physics/0408067},
author = {Kennel, Matthew B.},
eprint = {0408067},
journal = {arXiv preprint arXiv:0408067},
primaryClass = {physics},
title = {{KDTREE 2: Fortran 95 and C++ software to efficiently search for near neighbors in a multi-dimensional Euclidean space}},
url = {http://arxiv.org/abs/physics/0408067},
year = {2004}
}

@inproceedings{Schapire1999,
abstract = {Boosting is a general method for improving the accuracy of any given learning algorithm. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting's relationship to support-vector machines. Some examples of recent applications of boosting are also described.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.01136v1},
author = {Schapire, Robert E.},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {citeulike-article-id:765005},
eprint = {arXiv:1508.01136v1},
isbn = {3540440119},
issn = {10450823},
pages = {1401--1406},
title = {{A brief introduction to boosting}},
volume = {2},
year = {1999}
}

@article{Friedman2001,
abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for ruining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Friedman, Jerome H.},
doi = {DOI 10.1214/aos/1013203451},
eprint = {arXiv:1011.1669v3},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Boosting,Decision trees,Function estimation,Robust nonparametric regression},
number = {5},
pages = {1189--1232},
pmid = {21740230},
title = {{Greedy function approximation: A gradient boosting machine}},
volume = {29},
year = {2001}
}

@article{Lewis2000,
abstract = {A common goal of many clinical research studies is the development of a reliable clinical decision rule, which can be used to classify new patients into clinically-important categories. Examples of such clinical decision rules include triage rules, whether used in the out-of-hospital setting or in the emergency department, and rules used to classify patients into various risk categories so that appropriate decisions can be made regarding treatment or hospitalization. Traditional statistical methods are cumbersome to use, or of limited utility, in addressing these types of classification problems. There are a number of reasons for these difficulties. First, there are generally many possible predictor variables which makes the task of variable selection difficult. Traditional statistical methods are poorly suited for this sort of multiple comparison. Second, the predictor variables are rarely nicely distributed. Many clinical variables are not normally distributed and different groups of patients may have markedly different degrees of variation or variance. Third, complex interactions or patterns may exist in the data. For example, the value of one variable (e.g., age) may substantially affect the importance of another variable (e.g., weight). These types of interactions are generally difficult to model, and virtually impossible to model when the number of interactions and variables becomes substantial. Fourth, the results of traditional methods may be difficult to use. For example, a multivariate logistic regression model yields a probability of disease, which can be calculated using the regression coefficients and the characteristics of the patient, yet such models are rarely utilized in clinical practice. Clinicians generally do not think in terms of probability but, rather in terms of categories, such as low risk versus high risk. Regardless of the statistical methodology being used, the creation of a clinical decision rule requires a relatively large dataset. For each patient in the dataset, one variable (the dependent variable), records whether or not that patient had the condition which we hope to predict accurately in future patients. Examples might include significant injury after trauma, myocardial infarction, or subarachnoid hemorrhage in the setting of headache. In addition, other variables record the values of patient characteristics which we believe might help us to predict the value of the dependent variable. For example, if one hopes to predict the presence of subarachnoid hemorrhage, a possible predictor variable might be whether or not the patient's headache was sudden in onset; another possible predictor would be whether or not the patient has a history of similar headaches in the past. In many clinically-important settings, the number of possible predictor variables is quite large. Within the last 10 years, there has been increasing interest in the use of classification and regression tree (CART) analysis. CART analysis is a tree-building technique which is unlike traditional data analysis methods. It is ideally suited to the generation of clinical decision rules. Because CART analysis is unlike other analysis methods it has been accepted relatively slowly. Furthermore, the vast majority of statisticians have little or no experience with the technique. Other factors which limit CART's general acceptability are the complexity of the analysis and, until recently, the software required to perform CART analysis was difficult to use. Luckily, it is now possible to perform a CART analysis without a deep understanding of each of the multiple steps being completed by the software. In a number of studies, I have found CART to be quite effective for creating clinical decision rules which perform as well or better than rules developed using more traditional methods. In addition, CART is often able to uncover complex interactions between predictors which may be difficult or impossible to uncover using traditional multivariate techniques. The purpose of this lecture is to provide an overview of CART methodology, emphasizing practical use rather than the underlying statistical theory.},
author = {Lewis, Roger J and Ph, D and Street, West Carson},
doi = {10.1.1.95.4103},
journal = {2000 Annual Meeting of the Society for Academic Emergency Medicine},
number = {310},
pages = {14p},
title = {{An Introduction to Classification and Regression Tree ( CART ) Analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.4103{\&}rep=rep1{\&}type=pdf},
year = {2000}
}


@misc{Leach2006,
abstract = {ChemInform is a weekly Abstracting Service, delivering concise information at a glance that was extracted from about 200 leading journals. To access a ChemInform Abstract, please click on HTML or PDF.},
author = {Leach, Andrew R. and Shoichet, Brian K. and Peishoff, Catherine E.},
booktitle = {Journal of Medicinal Chemistry},
doi = {10.1021/jm060999m},
isbn = {0022-2623},
issn = {00222623},
number = {20},
pages = {5851--5855},
pmid = {17004700},
title = {{Prediction of protein-ligand interactions. Docking and scoring: Successes and gaps}},
volume = {49},
year = {2006}
}


@article{Friesner2004,
abstract = {Unlike other methods for docking ligands to the rigid 3D structure of a known protein receptor, Glide approximates a complete systematic search of the conformational, orientational, and positional space of the docked ligand. In this search, an initial rough positioning and scoring phase that dramatically narrows the search space is followed by torsionally flexible energy optimization on an OPLS-AA nonbonded potential grid for a few hundred surviving candidate poses. The very best candidates are further refined via a Monte Carlo sampling of pose conformation; in some cases, this is crucial to obtaining an accurate docked pose. Selection of the best docked pose uses a model energy function that combines empirical and force-field-based terms. Docking accuracy is assessed by redocking ligands from 282 cocrystallized PDB complexes starting from conformationally optimized ligand geometries that bear no memory of the correctly docked pose. Errors in geometry for the top-ranked pose are less than 1 A in nearly half of the cases and are greater than 2 A in only about one-third of them. Comparisons to published data on rms deviations show that Glide is nearly twice as accurate as GOLD and more than twice as accurate as FlexX for ligands having up to 20 rotatable bonds. Glide is also found to be more accurate than the recently described Surflex method.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Friesner, Richard A. and Banks, Jay L. and Murphy, Robert B. and Halgren, Thomas A. and Klicic, Jasna J. and Mainz, Daniel T. and Repasky, Matthew P. and Knoll, Eric H. and Shelley, Mee and Perry, Jason K. and Shaw, David E. and Francis, Perry and Shenkin, Peter S.},
doi = {10.1021/jm0306430},
eprint = {arXiv:1011.1669v3},
isbn = {0022-2623},
issn = {00222623},
journal = {Journal of Medicinal Chemistry},
number = {7},
pages = {1739--1749},
pmid = {15027865},
title = {{Glide: A New Approach for Rapid, Accurate Docking and Scoring. 1. Method and Assessment of Docking Accuracy}},
volume = {47},
year = {2004}
}

@article{Krammer2005,
abstract = {We present two new empirical scoring functions, LigScore1 and LigScore2, that attempt to accurately predict the binding affinity between ligand molecules and their protein receptors. The LigScore functions consist of three distinct terms that describe the van der Waals interaction, the polar attraction between the ligand and protein, and the desolvation penalty attributed to the binding of the polar ligand atoms to the protein and vice versa. Utilizing a regression approach on a data set of 118 protein-ligand complexes we have obtained a linear equation, LigScore2, using these three descriptors. LigScore2 has good predictability with regard to experimental pKi values yielding a correlation coefficient, r2, of 0.75 and a standard deviation of 1.04 over the training data set, which consists of a diverse set of proteins that span more than seven protein families. ?? 2004 Elsevier Inc. All rights reserved.},
author = {Krammer, Andr{\'{e}} and Kirchhoff, Paul D. and Jiang, X. and Venkatachalam, C. M. and Waldman, Marvin},
doi = {10.1016/j.jmgm.2004.11.007},
isbn = {1093-3263 (Print)},
issn = {10933263},
journal = {Journal of Molecular Graphics and Modelling},
keywords = {Binding affinity,Desolvation penalty,LigScore},
number = {5},
pages = {395--407},
pmid = {15781182},
title = {{LigScore: A novel scoring function for predicting binding affinities}},
volume = {23},
year = {2005}
}

@article{Huang2006,
abstract = {Ligand binding affinity prediction is one of the most important applications of computational chemistry. However, accurately ranking compounds with respect to their estimated binding affinities to a biomolecular target remains highly challenging. We provide an overview of recent work using molecular mechanics energy functions to address this challenge. We briefly review methods that use molecular dynamics and Monte Carlo simulations to predict absolute and relative ligand binding free energies, as well as our own work in which we have developed a physics-based scoring method that can be applied to hundreds of thousands of compounds by invoking a number of simplifying approximations. In our previous studies, we have demonstrated that our scoring method is a promising approach for improving the discrimination between ligands that are known to bind and those that are presumed not to, in virtual screening of large compound databases. In new results presented here, we explore several improvements to our computational method including modifying the dielectric constant used for the protein and ligand interiors, and empirically scaling energy terms to compensate for deficiencies in the energy model. Future directions for further improving our physics-based scoring method are also discussed.},
author = {Huang, Niu and Kalyanaraman, Chakrapani and Bernacki, Katarzyna and Jacobson, Matthew P},
doi = {10.1039/b608269f},
issn = {1463-9076},
journal = {Physical chemistry chemical physics : PCCP},
number = {44},
pages = {5166--5177},
pmid = {17203140},
title = {{Molecular mechanics methods for predicting protein-ligand binding.}},
volume = {8},
year = {2006}
}


@article{Mooij2005,
abstract = {We present a novel atom-atom potential derived from a database of protein-ligand complexes. First, we clarify the similarities and differences between two statistical potentials described in the literature, PMF and Drugscore. We highlight shortcomings caused by an important factor unaccounted for in their reference states, and describe a new potential, which we name the Astex Statistical Potential (ASP). ASP's reference state considers the difference in exposure of protein atom types towards ligand binding sites. We show that this new potential predicts binding affinities with an accuracy similar to that of Goldscore and Chemscore. We investigate the influence of the choice of reference state by constructing two additional statistical potentials that differ from ASP only in this respect. The reference states in these two potentials are defined along the lines of Drugscore and PMF. In docking experiments, the potential using the new reference state proposed for ASP gives better success rates than when these literature reference states were used; a success rate similar to the established scoring functions Goldscore and Chemscore is achieved with ASP. This is the case both for a large, general validation set of protein-ligand structures and for small test sets of actives against four pharmaceutically relevant targets. Virtual screening experiments for these targets show less discrimination between the different reference states in terms of enrichment. In addition, we describe how statistical potentials can be used in the construction of targeted scoring functions. Examples are given for cdk2, using four different targeted scoring functions, biased towards increasingly large target-specific databases. Using these targeted scoring functions, docking success rates as well as enrichments are significantly better than for the general ASP scoring function. Results improve with the number of structures used in the construction of the target scoring functions, thus illustrating that these targeted ASP potentials can be continuously improved as new structural data become available.},
author = {Mooij, W. T M and Verdonk, Marcel L.},
doi = {10.1002/prot.20588},
isbn = {0887-3585},
issn = {08873585},
journal = {Proteins: Structure, Function and Genetics},
keywords = {Docking,Protein-ligand interactions,Statistical potentials,Targeted scoring functions,Virtual screening},
number = {2},
pages = {272--287},
pmid = {16106379},
title = {{General and targeted statistical potentials for protein-ligand interactions}},
volume = {61},
year = {2005}
}

@article{Gohlke2000,
abstract = {The development and validation of a new knowledge-based scoring function (DrugScore) to describe the binding geometry of ligands in proteins is presented. It discriminates efficiently between well-docked ligand binding modes (root-mean-square deviation {\textless}2.0 A with respect to a crystallographically determined reference complex) and those largely deviating from the native structure, e.g. generated by computer docking programs. Structural information is extracted from crystallographically determined protein-ligand complexes using ReLiBase and converted into distance-dependent pair-preferences and solvent-accessible surface (SAS) dependent singlet preferences for protein and ligand atoms. Definition of an appropriate reference state and accounting for inaccuracies inherently present in experimental data is required to achieve good predictive power. The sum of the pair preferences and the singlet preferences is calculated based on the 3D structure of protein-ligand binding modes generated by docking tools. For two test sets of 91 and 68 protein-ligand complexes, taken from the Protein Data Bank (PDB), the calculated score recognizes poses generated by FlexX deviating {\textless}2 A from the crystal structure on rank 1 in three quarters of all possible cases. Compared to FlexX, this is a substantial improvement. For ligand geometries generated by DOCK, DrugScore is superior to the "chemical scoring" implemented into this tool, while comparable results are obtained using the "energy scoring" in DOCK. None of the presently known scoring functions achieves comparable power to extract binding modes in agreement with experiment. It is fast to compute, regards implicitly solvation and entropy contributions and produces correctly the geometry of directional interactions. Small deviations in the 3D structure are tolerated and, since only contacts to non-hydrogen atoms are regarded, it is independent from assumptions of protonation states.},
author = {Gohlke, H and Hendlich, M and Klebe, G},
doi = {10.1006/jmbi.1999.3371\rS0022-2836(99)93371-5 [pii]},
isbn = {0022-2836 (Print)$\backslash$r0022-2836 (Linking)},
issn = {0022-2836},
journal = {Journal of Molecular Biology},
keywords = {*Artificial Intelligence,*Protein Binding,Ligands,Protein Conformation,Surface Properties,Thermodynamics},
number = {2},
pages = {337--356},
pmid = {10623530},
title = {{Knowledge-based scoring function to predict protein-ligand interactions}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}db=PubMed{\&}dopt=Citation{\&}list{\_}uids=10623530$\backslash$nhttp://ac.els-cdn.com/S0022283699933715/1-s2.0-S0022283699933715-main.pdf?{\_}tid=eb8d0952-38c8-11e2-b722-00000aab0f6b{\&}acdnat=1354044817{\_}5649d11c7214e293a2},
volume = {295},
year = {2000}
}

@incollection{Abdi2003,
abstract = {PLS regression is a recent technique that generalizes and combines features from principal component analysis and multiple regression. Its goal is to predict or analyze a set of dependent variables from a set of independent variables or predictors. This prediction is achieved by extracting from the predictors a set of orthogonal factors called latent variables which have the best predictive power.},
author = {Abdi, Herv{\'{e}}},
booktitle = {Encyclopedia for research methods for the social sciences},
doi = {http://dx.doi.org/10.4135/9781412950589.n690},
isbn = {9781412950589},
issn = {15315487},
pages = {792--795},
pmid = {20539106},
title = {{Partial Least Squares (PLS) Regression}},
year = {2003}
}

@article{Baum2010,
abstract = {Additivity of functional group contributions to protein-ligand binding is a very popular concept in medicinal chemistry as the basis of rational design and optimized lead structures. Most of the currently applied scoring functions for docking build on such additivity models. Even though the limitation of this concept is well known, case studies examining in detail why additivity fails at the molecular level are still very scarce. The present study shows, by use of crystal structure analysis and isothermal titration calorimetry for a congeneric series of thrombin inhibitors, that extensive cooperative effects between hydrophobic contacts and hydrogen bond formation are intimately coupled via dynamic properties of the formed complexes. The formation of optimal lipophilic contacts with the surface of the thrombin S3 pocket and the full desolvation of this pocket can conflict with the formation of an optimal hydrogen bond between ligand and protein. The mutual contributions of the competing interactions depend on the size of the ligand hydrophobic substituent and influence the residual mobility of ligand portions at the binding site. Analysis of the individual crystal structures and factorizing the free energy into enthalpy and entropy demonstrates that binding affinity of the ligands results from a mixture of enthalpic contributions from hydrogen bonding and hydrophobic contacts, and entropic considerations involving an increasing loss of residual mobility of the bound ligands. This complex picture of mutually competing and partially compensating enthalpic and entropic effects determines the non-additivity of free energy contributions to ligand binding at the molecular level. ?? 2010 Elsevier Ltd.},
author = {Baum, Bernhard and Muley, Laveena and Smolinski, Michael and Heine, Andreas and Hangauer, David and Klebe, Gerhard},
doi = {10.1016/j.jmb.2010.02.007},
isbn = {1089-8638},
issn = {00222836},
journal = {Journal of Molecular Biology},
keywords = {Crystal structure analysis,Isothermal titration calorimetry,Ligand-protein interactions,Non-additivity of functional group contributions,Thrombin},
number = {4},
pages = {1042--1054},
pmid = {20156458},
title = {{Non-additivity of functional group contributions in protein-ligand binding: A comprehensive study by crystallography and isothermal titration calorimetry}},
volume = {397},
year = {2010}
}

@article{Li2013,
abstract = {Scoring functions have been widely used to assess protein?ligand binding affinity in structure-based drug discovery. However, currently commonly used scoring functions face some challenges including poor correlation between calculated scores and experimental binding affinities, target-dependent performance, and low sensitivity to analogues. In this account, we propose a new empirical scoring function termed ID-Score. ID-Score was established based on a comprehensive set of descriptors related to protein?ligand interactions; these descriptors cover nine categories: van der Waals interaction, hydrogen-bonding interaction, electrostatic interaction, $\pi$-system interaction, metal?ligand bonding interaction, desolvation effect, entropic loss effect, shape matching, and surface property matching. A total of 2278 complexes were used as the training set, and a modified support vector regression (SVR) algorithm was used to fit the experimental binding affinities. Evaluation results showed that ID-Score outperformed other selected commonly used scoring functions on a benchmark test set and showed considerable performance on a large independent test set. ID-Score also showed a consistent higher performance across different biological targets. Besides, it could correctly differentiate structurally similar ligands, indicating higher sensitivity to analogues. Collectively, the better performance of ID-Score enables it as a useful tool in assessing protein?ligand binding affinity in structure-based drug discovery as well as in lead optimization.},
author = {Li, Guo Bo and Yang, Ling Ling and Wang, Wen Jing and Li, Lin Li and Yang, Sheng Yong},
doi = {10.1021/ci300493w},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {3},
pages = {592--600},
pmid = {23394072},
title = {{ID-score: A new empirical scoring function based on a comprehensive set of descriptors related to protein-ligand interactions}},
volume = {53},
year = {2013}
}

@article{Ballester2010,
abstract = {Motivation: Accurately predicting the binding affinities of large sets of diverse proteinâ€“ligand complexes is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for analysing the outputs of molecular docking, which in turn is an important technique for drug discovery, chemical biology and structural biology. Each scoring function assumes a predetermined theory-inspired functional form for the relationship between the variables that characterize the complex, which also include parameters fitted to experimental or simulation data and its predicted binding affinity. The inherent problem of this rigid approach is that it leads to poor predictivity for those complexes that do not conform to the modelling assumptions. Moreover, resampling strategies, such as cross-validation or bootstrapping, are still not systematically used to guard against the overfitting of calibration data in parameter estimation for scoring functions.Results: We propose a novel scoring function (RF-Score) that circumvents the need for problematic modelling assumptions via non-parametric machine learning. In particular, Random Forest was used to implicitly capture binding effects that are hard to model explicitly. RF-Score is compared with the state of the art on the demanding PDBbind benchmark. Results show that RF-Score is a very competitive scoring function. Importantly, RF-Score's performance was shown to improve dramatically with training set size and hence the future availability of more high-quality structural and interaction data is expected to lead to improved versions of RF-Score.Contact: pedro.ballester@ebi.ac.uk; jbom@st-andrews.ac.ukSupplementary information: Supplementary data are available at Bioinformatics online.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Ballester, Pedro J. and Mitchell, John B O},
doi = {10.1093/bioinformatics/btq112},
eprint = {0-387-31073-8},
isbn = {0070428077},
issn = {13674803},
journal = {Bioinformatics},
number = {9},
pages = {1169--1175},
pmid = {20236947},
title = {{A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking}},
volume = {26},
year = {2010}
}

@article{Durrant2011,
abstract = {NNScore is a neural-network-based scoring function designed to aid the computational identification of small-molecule ligands. While the test cases included in the original NNScore article demonstrated the utility of the program, the application examples were limited. The purpose of the current work is to further confirm that neural-network scoring functions are effective, even when compared to the scoring functions of state-of-the-art docking programs, such as AutoDock, the most commonly cited program, and AutoDock Vina, thought to be two orders of magnitude faster. Aside from providing additional validation of the original NNScore function, we here present a second neural-network scoring function, NNScore 2.0. NNScore 2.0 considers many more binding characteristics when predicting affinity than does the original NNScore. The network output of NNScore 2.0 also differs from that of NNScore 1.0; rather than a binary classification of ligand potency, NNScore 2.0 provides a single estimate of the pK(d). To facilitate use, NNScore 2.0 has been implemented as an open-source python script. A copy can be obtained from http://www.nbcr.net/software/nnscore/ .},
author = {Durrant, Jacob D. and McCammon, J. Andrew},
doi = {10.1021/ci2003889},
file = {:home/jose/Downloads/ci2003889.pdf:pdf},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {ML GRIB/Binding affinity prediction},
number = {11},
pages = {2897--2903},
pmid = {22017367},
title = {{NNScore 2.0: A neural-network receptor-ligand scoring function}},
volume = {51},
year = {2011}
}


@article{Zilian2013,
abstract = {A major shortcoming of empirical scoring functions for protein-ligand complexes is the low degree of correlation between predicted and experimental binding affinities, as frequently observed not only for large and diverse data sets but also for SAR series of individual targets. Improvements can be envisaged by developing new descriptors, employing larger training sets of higher quality, and resorting to more sophisticated regression methods. Herein, we describe the use of SFCscore descriptors to develop an improved scoring function by means of a PDBbind training set of 1005 complexes in combination with random forest for regression. This provided SFCscoreRF as a new scoring function with significantly improved performance on the PDBbind and CSAR-NRC HiQ benchmarks in comparison to previously developed SFCscore functions. A leave-cluster-out cross-validation and performance in the CSAR 2012 scoring exercise point out remaining limitations but also directions for further improvements of SFCscoreRF and empirical scoring functions in general.},
author = {Zilian, David and Sotri, Christoph a},
doi = {10.1021/ci400120b},
file = {:home/jose/Downloads/ci400120b.pdf:pdf},
isbn = {1549-9596},
issn = {1549-960X},
journal = {Journal of chemical information and modeling},
mendeley-groups = {ML GRIB/Binding affinity prediction},
pages = {1923--1933},
pmid = {23705795},
title = {{SFCscoreRF: A Random Forest-Based Scoring Function for Improved A ffi nity Prediction of Protein - Ligand Complexes}},
volume = {53},
year = {2013}
}

@article{Labute2000,
abstract = {Three sets of molecular descriptors computable from connection table information are defined. These descriptors are based on atomic contributions to van der Waals surface area, log P (octanol/water), molar refractivity, and partial charge. The descriptors are applied to the construction of QSAR/QSPR models for boiling point, vapor pressure, free energy of solvation in water, solubility in water, thrombin/trypsin/factor Xa activity, blood-brain barrier permeability, and compound classification. The wide applicability of these descriptors suggests uses in QSAR/QSPR, combinatorial library design, and molecular diversity work.},
author = {Labute, Paul},
doi = {10.1016/S1093-3263(00)00068-1},
isbn = {1093-3263},
issn = {10933263},
journal = {Journal of Molecular Graphics and Modelling},
keywords = {Molecular descriptors,Molecular diversity,QSAR},
number = {4-5},
pages = {464--477},
pmid = {11143563},
title = {{A widely applicable set of descriptors}},
volume = {18},
year = {2000}
}

@article{Ballester2014,
abstract = {Predicting the binding affinities of large sets of diverse molecules against a range of macromolecular targets is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for exploiting and analyzing the outputs of docking, which is in turn an important tool in problems such as structure-based drug design. Classical scoring functions assume a predetermined theory-inspired functional form for the relationship between the variables that describe an experimentally determined or modeled structure of a protein?ligand complex and its binding affinity. The inherent problem of this approach is in the difficulty of explicitly modeling the various contributions of intermolecular interactions to binding affinity. New scoring functions based on machine-learning regression models, which are able to exploit effectively much larger amounts of experimental data and circumvent the need for a predetermined functional form, have already been shown to outperform a broad range of state-of-the-art scoring functions in a widely used benchmark. Here, we investigate the impact of the chemical description of the complex on the predictive power of the resulting scoring function using a systematic battery of numerical experiments. The latter resulted in the most accurate scoring function to date on the benchmark. Strikingly, we also found that a more precise chemical description of the protein?ligand complex does not generally lead to a more accurate prediction of binding affinity. We discuss four factors that may contribute to this result: modeling assumptions, codependence of representation and regression, data restricted to the bound state, and conformational heterogeneity in data.},
author = {Ballester, Pedro J. and Schreyer, Adrian and Blundell, Tom L.},
doi = {10.1021/ci500091r},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {3},
pages = {944--955},
pmid = {24528282},
title = {{Does a more precise chemical description of protein-ligand complexes lead to more accurate prediction of binding affinity?}},
volume = {54},
year = {2014}
}

@article{Dunbar2013,
abstract = {A major goal in drug design is the improvement of computational methods for docking and scoring. The Community Structure Activity Resource (CSAR) has collected several data sets from industry and added in-house data sets that may be used for this purpose ( www.csardock.org). CSAR has currently obtained data from Abbott, GlaxoSmithKline, and Vertex and is working on obtaining data from several others. Combined with our in-house projects, we are providing a data set consisting of 6 protein targets, 647 compounds with biological affinities, and 82 crystal structures. Multiple congeneric series are available for several targets with a few representative crystal structures of each of the series. These series generally contain a few inactive compounds, usually not available in the literature, to provide an upper bound to the affinity range. The affinity ranges are typically 3-4 orders of magnitude per series. For our in-house projects, we have had compounds synthesized for biological testing. Affinities were measured by Thermofluor, Octet RED, and isothermal titration calorimetry for the most soluble. This allows the direct comparison of the biological affinities for those compounds, providing a measure of the variance in the experimental affinity. It appears that there can be considerable variance in the absolute value of the affinity, making the prediction of the absolute value ill-defined. However, the relative rankings within the methods are much better, and this fits with the observation that predicting relative ranking is a more tractable problem computationally. For those in-house compounds, we also have measured the following physical properties: logD, logP, thermodynamic solubility, and pK(a). This data set also provides a substantial decoy set for each target consisting of diverse conformations covering the entire active site for all of the 58 CSAR-quality crystal structures. The CSAR data sets (CSAR-NRC HiQ and the 2012 release) provide substantial, publically available, curated data sets for use in parametrizing and validating docking and scoring methods.},
author = {Dunbar, James B. and Smith, Richard D. and Damm-Ganamet, Kelly L. and Ahmed, Aqeel and Esposito, Emilio Xavier and Delproposto, James and Chinnaswamy, Krishnapriya and Kang, You Na and Kubish, Ginger and Gestwicki, Jason E. and Stuckey, Jeanne A. and Carlson, Heather A.},
doi = {10.1021/ci4000486},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {8},
pages = {1842--1852},
pmid = {23617227},
title = {{CSAR data set release 2012: Ligands, affinities, complexes, and docking decoys}},
volume = {53},
year = {2013}
}

@article{Wang2004,
abstract = {We have screened the entire Protein Data Bank (Release No. 103, January 2003) and identified 5671 protein-ligand complexes out of 19 621 experimental structures. A systematic examination of the primary references of these entries has led to a collection of binding affinity data (K(d), K(i), and IC(50)) for a total of 1359 complexes. The outcomes of this project have been organized into a Web-accessible database named the PDBbind database.},
author = {Wang, Renxiao and Fang, Xueliang and Lu, Yipin and Wang, Shaomeng},
doi = {10.1021/jm030580l},
isbn = {0022-2623},
issn = {00222623},
journal = {Journal of Medicinal Chemistry},
number = {12},
pages = {2977--2980},
pmid = {15163179},
title = {{The PDBbind database: Collection of binding affinities for protein-ligand complexes with known three-dimensional structures}},
volume = {47},
year = {2004}
}

@article{Doerr2016,
abstract = {Recent advances in molecular simulations have allowed scientists to investigate slower biological processes than ever before. Together with these advances came an explosion of data that has transformed a traditionally computing-bound into a data-bound problem. Here, we present HTMD, a programmable, extensible platform written in Python that aims to solve the data generation and analysis problem as well as increase reproducibility by providing a complete workspace for simulation-based discovery. So far, HTMD includes system building for CHARMM and AMBER force fields, projection methods, clustering, molecular simulation production, adaptive sampling, an Amazon cloud interface, Markov state models, and visualization. As a result, a single, short HTMD script can lead from a PDB structure to useful quantities such as relaxation time scales, equilibrium populations, metastable conformations, and kinetic rates. In this paper, we focus on the adaptive sampling and Markov state modeling features.},
author = {Doerr, S. and Harvey, M. J. and No\'e, Frank and {De Fabritiis}, G.},
doi = {10.1021/acs.jctc.6b00049},
isbn = {1549-9626 (Electronic)$\backslash$r1549-9618 (Linking)},
issn = {15499626},
journal = {Journal of Chemical Theory and Computation},
number = {4},
pages = {1845--1852},
pmid = {26949976},
title = {{HTMD: High-Throughput Molecular Dynamics for Molecular Discovery}},
volume = {12},
year = {2016}
}
















